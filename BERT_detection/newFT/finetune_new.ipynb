{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c950d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda5de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数シードの固定\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定ファイルの読み込み\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの前処理\n",
    "def format_string(string):\n",
    "    return string.replace('\\\\n', ' ')\n",
    "\n",
    "def combine_sentences(utr, res):\n",
    "    return f\"{format_string(utr)} [SEP] {format_string(res)}\"\n",
    "\n",
    "def load_and_preprocess_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['text'] = df.apply(\n",
    "        lambda x: combine_sentences(x['Utterance'], x['Response']), axis=1)\n",
    "    df = df.drop(columns=['Utterance', 'Response'])\n",
    "    df = df.sample(frac=1, random_state=config['seed']).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの作成\n",
    "def create_dataloaders(texts, labels, tokenizer, max_length, batch_size):\n",
    "    dataset = TextDataset(texts, labels, tokenizer, max_length)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cac3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの初期化\n",
    "def initialize_model(model_name, num_labels, id2label, label2id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73839bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習パラメータの設定\n",
    "def configure_optimizer(model, learning_rate, weight_decay):\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    named_params = list(model.named_parameters())  # キャッシュ\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in named_params if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in named_params if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def configure_scheduler(optimizer, num_training_steps, num_warmup_steps_ratio):\n",
    "    num_warmup_steps = int(num_training_steps * num_warmup_steps_ratio)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"cosine\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "    return lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習情報の記録\n",
    "def get_training_info(config):\n",
    "    training_info = {}\n",
    "    training_info['start_time'] = datetime.datetime.now().isoformat()\n",
    "    training_info['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    training_info['model_name'] = config['model_name']\n",
    "    training_info['max_length'] = config['max_length']\n",
    "    training_info['batch_size'] = config['batch_size']\n",
    "    training_info['num_epochs'] = config['num_epochs']\n",
    "    training_info['learning_rate'] = config['learning_rate']\n",
    "    training_info['weight_decay'] = config['weight_decay']\n",
    "    training_info['num_warmup_steps'] = int(config['num_epochs'] * len(train_dataloader) * config['num_warmup_steps_ratio'])\n",
    "    training_info['id2label'] = config['id2label']\n",
    "    training_info['label2id'] = config['label2id']\n",
    "    return training_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca6975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの学習\n",
    "def train(model, train_dataloader, val_dataloader, optimizer, lr_scheduler, num_epochs, device, early_stopping_patience):\n",
    "    progress_bar = tqdm(range(len(train_dataloader) * num_epochs))\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_metric = evaluate.load(\"accuracy\")\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss_val = outputs.loss\n",
    "            total_loss += loss_val.item()\n",
    "            loss_val.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            train_metric.add_batch(\n",
    "                predictions=predictions, references=batch['labels'])\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        train_metric = train_metric.compute()\n",
    "        train_losses.append(avg_train_loss)\n",
    "        train_accuracies.append(train_metric['accuracy'])\n",
    "\n",
    "        # 検証ループ\n",
    "        model.eval()\n",
    "        total_eval_loss = 0\n",
    "        val_progress_bar = tqdm(range(len(val_dataloader)))\n",
    "        metric = evaluate.load(\"accuracy\")\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "                loss_val = outputs.loss\n",
    "                total_eval_loss += loss_val.item()\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            metric.add_batch(predictions=predictions,\n",
    "                             references=batch['labels'])\n",
    "            val_progress_bar.update(1)\n",
    "        avg_val_loss = total_eval_loss / len(val_dataloader)\n",
    "        eval_metric = metric.compute()\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_accuracies.append(eval_metric['accuracy'])\n",
    "\n",
    "        print(f\"epoch {epoch+1}: train_loss: {avg_train_loss:.4f}, val_loss: {avg_val_loss:.4f}, accuracy: {eval_metric['accuracy']:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(\n",
    "                f\"Early stopping triggered at epoch {epoch+1}.\"\n",
    "            )\n",
    "            break\n",
    "    return train_accuracies, val_accuracies, train_losses, val_losses, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fba1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価\n",
    "def evaluate_model(model, eval_dataloader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    eval_progress_bar = tqdm(range(len(eval_dataloader)))\n",
    "    for batch in eval_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())\n",
    "        eval_progress_bar.update(1)\n",
    "\n",
    "    y_true = all_labels\n",
    "    y_preds = all_predictions\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_preds)\n",
    "    tn, fp, fn, tp = cm.flatten()\n",
    "\n",
    "    accuracy_eval = (tp + tn) / (tp + tn + fp +\n",
    "                                 fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / \n",
    "        (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return y_true, y_preds, cm, accuracy_eval, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea08848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価結果の表示\n",
    "def display_evaluation_metrics(y_true, y_preds, cm, accuracy_eval, precision, recall, f1, save_datetime, log_dir):\n",
    "    labels = ['NOTIRONY', 'IRONY']\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    fig_save_path = os.path.join(\n",
    "        log_dir, f\"confusion_matrix_{save_datetime}.png\")\n",
    "    plt.savefig(fig_save_path)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Accuracy : {accuracy_eval:.4f}\")\n",
    "    print(f\"Precision : {precision:.4f}\")\n",
    "    print(f\"Recall : {recall:.4f}\")\n",
    "    print(f\"F1 : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b448cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ログの保存\n",
    "def save_training_log_json(training_info, train_results, eval_results, raw_answers, save_datetime, log_dir):\n",
    "    log_file = os.path.join(log_dir, f\"training_log_{save_datetime}.json\")\n",
    "    with open(log_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'training_info': training_info,\n",
    "            'train_results': train_results,\n",
    "            'raw_answers': raw_answers,\n",
    "            'eval_results': eval_results\n",
    "        }, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Training log saved to {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メイン処理\n",
    "def main():\n",
    "    # 設定ファイルの読み込み\n",
    "    config_file = 'config.json'\n",
    "    config = load_config(config_file)\n",
    "\n",
    "    # 乱数シードの固定\n",
    "    set_seed(config['seed'])\n",
    "\n",
    "    # デバイスの設定\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "    # データセットの準備\n",
    "    df = load_and_preprocess_data(config['train_csv'])\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        df['text'].tolist(), df['label'].tolist(), test_size=0.2, random_state=config['seed']\n",
    "    )\n",
    "\n",
    "    # モデルとトークナイザーの初期化\n",
    "    tokenizer, model = initialize_model(\n",
    "        config['model_name'], 2, config['id2label'], config['label2id'])\n",
    "\n",
    "    # データローダーの作成\n",
    "    train_dataloader = create_dataloaders(\n",
    "        train_texts, train_labels, tokenizer, config['max_length'], config['batch_size'])\n",
    "    val_dataloader = create_dataloaders(\n",
    "        val_texts, val_labels, tokenizer, config['max_length'], config['batch_size'])\n",
    "\n",
    "    # モデルをGPUに転送\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # 学習パラメータの設定\n",
    "    optimizer = configure_optimizer(\n",
    "        model, config['learning_rate'], config['weight_decay'])\n",
    "    num_training_steps = config['num_epochs'] * len(train_dataloader)\n",
    "    lr_scheduler = configure_scheduler(\n",
    "        optimizer, num_training_steps, config['num_warmup_steps_ratio']\n",
    "    )\n",
    "    training_info = get_training_info(config)\n",
    "\n",
    "    # モデルの学習\n",
    "    train_accuracies, val_accuracies, train_losses, val_losses, best_model = train(\n",
    "        model, train_dataloader, val_dataloader, optimizer, lr_scheduler, config['num_epochs'], DEVICE, config['early_stopping_patience']\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    end_time = datetime.datetime.now().isoformat()\n",
    "    training_info['end_time'] = end_time\n",
    "    train_time = datetime.datetime.strptime(end_time, '%Y-%m-%dT%H:%M:%S.%f') - \n",
    "        datetime.datetime.strptime(\n",
    "            training_info['start_time'], '%Y-%m-%dT%H:%M:%S.%f')\n",
    "    training_info['train_time'] = str(train_time)\n",
    "\n",
    "    train_results = {\n",
    "        'train_accuracy': train_accuracies,\n",
    "        'train_loss': train_losses,\n",
    "        'val_accuracy': val_accuracies,\n",
    "        'val_loss': val_losses\n",
    "    }\n",
    "\n",
    "    # 評価用データセットの準備\n",
    "    df_eva = load_and_preprocess_data(config['eval_csv'])\n",
    "    eval_texts = df_eva['text'].tolist()\n",
    "    eval_labels = df_eva['label'].tolist()\n",
    "\n",
    "    # 評価用データローダーを作成\n",
    "    eval_dataloader = create_dataloaders(\n",
    "        eval_texts, eval_labels, tokenizer, config['max_length'], config['batch_size'])\n",
    "\n",
    "    # モデルの評価\n",
    "    y_true, y_preds, cm, accuracy_eval, precision, recall, f1 = evaluate_model(\n",
    "        model, eval_dataloader, DEVICE\n",
    "    )\n",
    "\n",
    "    # 評価結果の表示\n",
    "    save_datetime = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    log_dir = config['log_dir']\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    display_evaluation_metrics(\n",
    "        y_true, y_preds, cm, accuracy_eval, precision, recall, f1, save_datetime, log_dir\n",
    "    )\n",
    "\n",
    "    raw_answers = {\n",
    "        'TruePositive': str(cm[1, 1]),\n",
    "        'TrueNegative': str(cm[0, 0]),\n",
    "        'FalsePositive': str(cm[0, 1]),\n",
    "        'FalseNegative': str(cm[1, 0])\n",
    "    }\n",
    "\n",
    "    eval_results = {\n",
    "        'accuracy': accuracy_eval,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "    # ログの保存\n",
    "    save_training_log_json(training_info, train_results,\n",
    "                           eval_results, raw_answers, save_datetime, log_dir)\n",
    "\n",
    "    # モデルの保存\n",
    "    model_dir = config['model_dir']\n",
    "    model_save_path = os.path.join(model_dir, f\"model_{save_datetime}\")\n",
    "    tokenizer_save_path = os.path.join(\n",
    "        model_dir, f\"tokenizer_{save_datetime}\")\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "    print(\"Fine-tuning completed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 乱数シードの固定\n",
    "    SEED = 42\n",
    "    set_seed(SEED)\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
